#!/bin/sh
#
#   Resource Agent for managing lustre server services.
#
#   License:      GNU General Public License (GPL)
#   (c) 2008-2010 John Doe, Jane Roe,

# Initialization:
: ${OCF_FUNCTIONS_DIR=${OCF_ROOT}/lib/heartbeat}
. ${OCF_FUNCTIONS_DIR}/ocf-shellfuncs
RESOURCE_DIR=$(dirname $0)

lustre_meta_data() {
    cat <<EOF
<?xml version="1.0"?>
<!DOCTYPE resource-agent SYSTEM "ra-api-1.dtd">
<resource-agent name="lustre" version="0.1">
  <version>0.1</version>
  <longdesc lang="en">
This is a Resource Agent that manages a single lustre, ZFS OSD backed
service (MGS, MDT, or OST).
  </longdesc>
  <shortdesc lang="en">Lustre ZFS OSD resource agent</shortdesc>
  <parameters>
    <parameter name="dataset" unique="0" required="1">
      <longdesc lang="en">
      Name of the ZFS dataset on which the Lustre service lives.
      </longdesc>
      <shortdesc lang="en">ZFS dataset name</shortdesc>
      <content type="string"/>
    </parameter>
    <parameter name="mountpoint" unique="0" required="1">
      <longdesc lang="en">
      Path of the mountpoint where the ZFS dataset will be mounted to launch the Lustre service.
      </longdesc>
      <shortdesc lang="en">Mount point for Lustre service</shortdesc>
      <content type="string"/>
    </parameter>
  </parameters>
  <actions>
    <action name="start"        timeout="300" />
    <action name="stop"         timeout="300" />
    <action name="monitor"      timeout="60"
                                interval="10" depth="0" />
    <action name="meta-data"    timeout="5" />
    <action name="validate-all"   timeout="20" />
  </actions>
</resource-agent>
EOF
}

lustre_monitor() {
    # exit immediately if configuration is not valid
    lustre_validate_all || exit $?

    if [ -d /proc/fs/lustre/osd-zfs ] ; then
	mntdevs=$(ls /proc/fs/lustre/osd-zfs/*/mntdev 2>/dev/null)
	for mntdev_path in $mntdevs ; do
	    mntdev=$(cat $mntdev_path 2>/dev/null)
	    if [ $mntdev = $OCF_RESKEY_dataset ] ; then
		ocf_log debug "$OCF_RESKEY_dataset found in $mntdev_path"
		return $OCF_SUCCESS
	    fi
	done
    fi

    return $OCF_NOT_RUNNING
}

lustre_validate_all() {
    # Test for configuration errors first
    # FIXME - add check for $OCF_RESKEY_data - nonzero, and looks like a zfs dataset
    #if ! ocf_is_decimal $OCF_RESKEY_eggs; then
    #   ocf_log err "eggs is not numeric!"
    #   exit $OCF_ERR_CONFIGURED
    #fi

    # Test for required binaries
    #check_binary lctl

    # Check for data directory (this may be on shared storage, so
    # disable this test during probes)
    #if ! ocf_is_probe; then
    #   if ! [ -d $OCF_RESKEY_datadir ]; then
    #      ocf_log err "$OCF_RESKEY_datadir does not exist or is not a directory!"
    #      exit $OCF_ERR_INSTALLED
    #   fi
    #fi

    return $OCF_SUCCESS
}

# If $hook_name file exists, run it.  Used to provide {pre,post}-{start,stop}
# hooks.  The executables used for hooks must adhere to the OCF Resource Agent
# Developer's guide with regards to exit codes and general behavior.
lustre_hook() {
    hook_name=$1

    if [ "$hook_name" != "lustre_pre_start" ]   && \
        [ "$hook_name" != "lustre_post_start" ] && \
        [ "$hook_name" != "lustre_pre_stop" ]   && \
        [ "$hook_name" != "lustre_post_stop" ]; then
        exit $OCF_ERR_GENERIC
    fi

    if [ -f "$RESOURCE_DIR/$hook_name" ]; then
        if [ -x "$RESOURCE_DIR/$hook_name" ]; then
            ocf_log info "Executing $hook_name"
            ocf_run $RESOURCE_DIR/$hook_name
            return $?
        else
            ocf_log error "OCF $hook_name file exists but is not executable!"
            return $OCF_ERR_PERM
        fi
    else
        return $OCF_SUCCESS
    fi
}

lustre_start() {
    # exit immediately if configuration is not valid
    lustre_validate_all || exit $?

    if lustre_monitor; then
        ocf_log info "ZFS dataset $OCF_RESKEY_dataset in use by lustre"
        return $OCF_SUCCESS
    fi

    # Run the pre-start script if it exists
    lustre_hook lustre_pre_start

    # actually start up the resource here (make sure to immediately
    # exit with an $OCF_ERR_ error code if anything goes seriously
    # wrong)
    # Note that OCF_ERR_GENERIC is a soft error, and the resource manager
    # may attempt to try this again on the same node.
    if [ ! -d $OCF_RESKEY_mountpoint ]; then
        ocf_run -q mkdir -p $OCF_RESKEY_mountpoint || exit $OCF_ERR_ARGS
    fi
    ocf_run -q mount -t lustre $OCF_RESKEY_dataset $OCF_RESKEY_mountpoint || exit $OCF_ERR_GENERIC

    # After the resource has been started, check whether it started up
    # correctly. If the resource starts asynchronously, the agent may
    # spin on the monitor function here -- if the resource does not
    # start up within the defined timeout, the cluster manager will
    # consider the start action failed
    while ! lustre_monitor; do
        ocf_log debug "ZFS dataset $OCF_RESKEY_dataset not yet in use by Lustre"
        sleep 1
    done

    # Run the post-start script if it exists
    lustre_hook lustre_post_start

    # only return $OCF_SUCCESS if _everything_ succeeded as expected
    return $OCF_SUCCESS
}

lustre_stop() {
    local rc

    # exit immediately if configuration is not valid
    lustre_validate_all || exit $?

    # Run the pre_stop script if it exists
    lustre_hook lustre_pre_stop

    lustre_monitor
    rc=$?
    case "$rc" in
        "$OCF_SUCCESS")
            # Currently running. Normal, expected behavior.
            ocf_log debug "ZFS dataset $OCF_RESKEY_dataset is in use by Lustre"
            ;;
        "$OCF_NOT_RUNNING")
            # Currently not running. Nothing to do.
            ocf_log info "Resource is already stopped"
            return $OCF_SUCCESS
            ;;
    esac

    # actually shut down the resource here (make sure to immediately
    # exit with an $OCF_ERR_ error code if anything goes seriously
    # wrong)
    ocf_run -q umount $OCF_RESKEY_mountpoint || exit $OCF_ERR_GENERIC
    rmdir $OCF_RESKEY_mountpoint >/dev/null 2>&1

    # After the resource has been stopped, check whether it shut down
    # correctly. If the resource stops asynchronously, the agent may
    # spin on the monitor function here -- if the resource does not
    # shut down within the defined timeout, the cluster manager will
    # consider the stop action failed
    while lustre_monitor; do
        ocf_log debug "Resource has not stopped yet, waiting"
        sleep 1
    done

    # Run the post-stop script if it exists
    lustre_hook lustre_post_stop

    # only return $OCF_SUCCESS if _everything_ succeeded as expected
    return $OCF_SUCCESS

}

# Make sure meta-data and usage always succeed
case $__OCF_ACTION in
meta-data)      lustre_meta_data
                exit $OCF_SUCCESS
                ;;
usage|help)     lustre_usage
                exit $OCF_SUCCESS
                ;;
esac

# Anything other than meta-data and usage must pass validation
lustre_validate_all || exit $?

# Translate each action into the appropriate function call
case $__OCF_ACTION in
start)          lustre_start;;
stop)           lustre_stop;;
status|monitor) lustre_monitor;;
validate-all)   lustre_validate_all;;
*)              lustre_usage
                exit $OCF_ERR_UNIMPLEMENTED
                ;;
esac
rc=$?

# The resource agent may optionally log a debug message
ocf_log debug "${OCF_RESOURCE_INSTANCE} $__OCF_ACTION returned $rc"
exit $rc
