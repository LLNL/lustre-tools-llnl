#!/bin/sh
#
#   Resource Agent for managing lustre server services.
#
# This file is part of lustre-tools-llnl.
#
# SPDX-License-Identifier: GPL-2.0
# See [LICENSE-GPL-2.0](https://github.com/LLNL/lustre-tools-llnl/LICENSE-GPL-2.0)
#
# Copyright (c) 2011, Lawrence Livermore National Security, LLC.
# Produced at the Lawrence Livermore National Laboratory.
# LLNL-CODE-468512

# Initialization:
: ${OCF_FUNCTIONS_DIR=${OCF_ROOT}/lib/heartbeat}
. ${OCF_FUNCTIONS_DIR}/ocf-shellfuncs

lustre_meta_data() {
    cat <<EOF
<?xml version="1.0"?>
<!DOCTYPE resource-agent SYSTEM "ra-api-1.dtd">
<resource-agent name="lustre" version="0.1">
  <version>0.1</version>
  <longdesc lang="en">
This is a Resource Agent that manages a single lustre, ZFS OSD backed
service (MGS, MDT, or OST).
  </longdesc>
  <shortdesc lang="en">Lustre ZFS OSD resource agent</shortdesc>
  <parameters>
    <parameter name="dataset" unique="0" required="1">
      <longdesc lang="en">
      Name of the ZFS dataset on which the Lustre service lives.
      </longdesc>
      <shortdesc lang="en">ZFS dataset name</shortdesc>
      <content type="string"/>
    </parameter>
    <parameter name="mountpoint" unique="0" required="1">
      <longdesc lang="en">
      Path of the mountpoint where the ZFS dataset will be mounted to launch the Lustre service.
      </longdesc>
      <shortdesc lang="en">Mount point for Lustre service</shortdesc>
      <content type="string"/>
    </parameter>
    <parameter name="post_mount_cmd" unique="0" required="0">
      <longdesc lang="en">
      Command run after mounting the target. Failure results in umount.
      </longdesc>
      <shortdesc lang="en">command run after target mount</shortdesc>
      <content type="string"/>
    </parameter>
  </parameters>
  <actions>
    <action name="start"        timeout="300" />
    <action name="stop"         timeout="300" />
    <action name="monitor"      timeout="60"
                                interval="10" depth="0" />
    <action name="meta-data"    timeout="5" />
    <action name="validate-all"   timeout="20" />
  </actions>
</resource-agent>
EOF
}

lustre_monitor() {
    # exit immediately if configuration is not valid
    lustre_validate_all || exit $?

    mntdevs=$(ls /{proc,sys}/fs/lustre/osd-zfs/*/mntdev 2>/dev/null)
    if [ -z "${mntdevs}" ]; then
        ocf_log info "No mntdev found in proc or sys"
        return $OCF_NOT_RUNNING
    fi

    for mntdev_path in $mntdevs ; do
        mntdev=$(cat $mntdev_path 2>/dev/null)
        if [ $mntdev = $OCF_RESKEY_dataset ] ; then
            ocf_log debug "$OCF_RESKEY_dataset found in $mntdev_path"
            return $OCF_SUCCESS
        else
            ocf_log debug "$OCF_RESKEY_dataset does not match $mntdev"
        fi
    done

    return $OCF_NOT_RUNNING
}

lustre_validate_all() {
    # Test for configuration errors first
    # FIXME - add check for $OCF_RESKEY_data - nonzero, and looks like a zfs dataset
    #if ! ocf_is_decimal $OCF_RESKEY_eggs; then
    #   ocf_log err "eggs is not numeric!"
    #   exit $OCF_ERR_CONFIGURED
    #fi

    # Test for required binaries
    #check_binary lctl

    # Check for data directory (this may be on shared storage, so
    # disable this test during probes)
    #if ! ocf_is_probe; then
    #   if ! [ -d $OCF_RESKEY_datadir ]; then
    #      ocf_log err "$OCF_RESKEY_datadir does not exist or is not a directory!"
    #      exit $OCF_ERR_INSTALLED
    #   fi
    #fi

    return $OCF_SUCCESS
}


lustre_start() {
    # exit immediately if configuration is not valid
    lustre_validate_all || exit $?

    if lustre_monitor; then
        ocf_log info "ZFS dataset $OCF_RESKEY_dataset in use by lustre"
        return $OCF_SUCCESS
    fi

    # actually start up the resource here (make sure to immediately
    # exit with an $OCF_ERR_ error code if anything goes seriously
    # wrong)
    # Note that OCF_ERR_GENERIC is a soft error, and the resource manager
    # may attempt to try this again on the same node.
    if [ ! -d $OCF_RESKEY_mountpoint ]; then
        ocf_run -q mkdir -p $OCF_RESKEY_mountpoint || exit $OCF_ERR_ARGS
    fi
    ocf_run -q mount -t lustre $OCF_RESKEY_dataset $OCF_RESKEY_mountpoint || exit $OCF_ERR_GENERIC

    # After the resource has been started, check whether it started up
    # correctly. If the resource starts asynchronously, the agent may
    # spin on the monitor function here -- if the resource does not
    # start up within the defined timeout, the cluster manager will
    # consider the start action failed
    while ! lustre_monitor; do
        ocf_log debug "ZFS dataset $OCF_RESKEY_dataset not yet in use by Lustre"
        sleep 1
    done

    if [ -n "$OCF_RESKEY_post_mount_cmd" ]; then
        ocf_run -q $OCF_RESKEY_post_mount_cmd $OCF_RESKEY_dataset $OCF_RESKEY_mountpoint
        if [ $? -ne 0 ]; then
            ocf_log err "FATAL ERROR: umounting Lustre $OCF_RESKEY_dataset from $OCF_RESKEY_mountpoint due to $OCF_RESKEY_post_mount_cmd failure"
            ocf_run -q umount $OCF_RESKEY_mountpoint
            exit $OCF_ERR_GENERIC
        fi
    fi

    # only return $OCF_SUCCESS if _everything_ succeeded as expected
    return $OCF_SUCCESS
}

lustre_stop() {
    local rc

    # exit immediately if configuration is not valid
    lustre_validate_all || exit $?

    lustre_monitor
    rc=$?
    case "$rc" in
        "$OCF_SUCCESS")
            # Currently running. Normal, expected behavior.
            ocf_log debug "ZFS dataset $OCF_RESKEY_dataset is in use by Lustre"
            ;;
        "$OCF_NOT_RUNNING")
            # Currently not running. Nothing to do.
            ocf_log info "Resource is already stopped"
            return $OCF_SUCCESS
            ;;
    esac

    # actually shut down the resource here (make sure to immediately
    # exit with an $OCF_ERR_ error code if anything goes seriously
    # wrong)
    ocf_run -q umount $OCF_RESKEY_mountpoint || exit $OCF_ERR_GENERIC
    rmdir $OCF_RESKEY_mountpoint >/dev/null 2>&1

    # After the resource has been stopped, check whether it shut down
    # correctly. If the resource stops asynchronously, the agent may
    # spin on the monitor function here -- if the resource does not
    # shut down within the defined timeout, the cluster manager will
    # consider the stop action failed
    while lustre_monitor; do
        ocf_log debug "Resource has not stopped yet, waiting"
        sleep 1
    done

    # only return $OCF_SUCCESS if _everything_ succeeded as expected
    return $OCF_SUCCESS

}

# Make sure meta-data and usage always succeed
case $__OCF_ACTION in
meta-data)      lustre_meta_data
                exit $OCF_SUCCESS
                ;;
usage|help)     lustre_usage
                exit $OCF_SUCCESS
                ;;
esac

# Anything other than meta-data and usage must pass validation
lustre_validate_all || exit $?

# Translate each action into the appropriate function call
case $__OCF_ACTION in
start)          lustre_start;;
stop)           lustre_stop;;
status|monitor) lustre_monitor;;
validate-all)   lustre_validate_all;;
*)              lustre_usage
                exit $OCF_ERR_UNIMPLEMENTED
                ;;
esac
rc=$?

# The resource agent may optionally log a debug message
ocf_log debug "${OCF_RESOURCE_INSTANCE} $__OCF_ACTION returned $rc"
exit $rc
